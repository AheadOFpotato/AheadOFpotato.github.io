---
---

@article{hu2024casebasedrulebasedtransformersmath,
      abbr={ICML2024},
      title={Case-Based or Rule-Based: How Do Transformers Do the Math?}, 
      author={Yi Hu and Xiaojuan Tang and Haotong Yang and Muhan Zhang},
      year={2024},
      eprint={2402.17709},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      paper={https://arxiv.org/abs/2402.17709},
      selected={true},
      poster={https://icml.cc/media/PosterPDFs/ICML%202024/35020.png?t=1720534634.9898195},
      code={https://github.com/GraphPKU/Case_or_Rule}
}

@article{hu2023codepromptingneuralsymbolic,
      abbr={preprint},
      title={Code Prompting: a Neural Symbolic Method for Complex Reasoning in Large Language Models}, 
      author={Yi Hu and Haotong Yang and Zhouchen Lin and Muhan Zhang},
      year={2023},
      eprint={2305.18507},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      paper={https://arxiv.org/abs/2305.18507}, 
}

@article{yang2024numbercookbooknumberunderstanding,
      abbr={ICLR2025},
      title={Number Cookbook: Number Understanding of Language Models and How to Improve It}, 
      author={Haotong Yang and Yi Hu and Shijia Kang and Zhouchen Lin and Muhan Zhang},
      year={2024},
      eprint={2411.03766},
      selected={true},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      paper={https://arxiv.org/abs/2411.03766}, 
      code={https://github.com/GraphPKU/number_cookbook}
}

@article{xu2025redstardoesscalinglongcot,
      abbr={preprint},
      title={RedStar: Does Scaling Long-CoT Data Unlock Better Slow-Reasoning Systems?}, 
      author={Haotian Xu and Xing Wu and Weinong Wang and Zhongzhi Li and Da Zheng and Boyuan Chen and Yi Hu and Shijia Kang and Jiaming Ji and Yingying Zhang and Zhijiang Guo and Yaodong Yang and Muhan Zhang and Debing Zhang},
      year={2025},
      eprint={2501.11284},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      paper={https://arxiv.org/abs/2501.11284},
      selected={true},
      code={https://huggingface.co/RedStar-Reasoning}
}

@article{hu2025traininglargelanguagemodels,
      abbr={preprint},
      title={Training Large Language Models to be Better Rule Followers}, 
      author={Yi Hu and Shijia Kang and Haotong Yang and Haotian Xu and Muhan Zhang},
      year={2025},
      eprint={2502.11525},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      selected={true},
      paper={https://arxiv.org/abs/2502.11525}, 
}

@misc{qiu2025phybenchholisticevaluationphysical,
      abbr={preprint},
      title={PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models}, 
      author={Shi Qiu and Shaoyang Guo and Zhuo-Yang Song and Yunbo Sun and Zeyu Cai and Jiashen Wei and Tianyu Luo and Yixuan Yin and Haoxu Zhang and Yi Hu and Chenyang Wang and Chencheng Tang and Haoling Chang and Qi Liu and Ziheng Zhou and Tianyu Zhang and Jingtian Zhang and Zhangyi Liu and Minghao Li and Yuku Zhang and Boxuan Jing and Xianqi Yin and Yutong Ren and Zizhuo Fu and Weike Wang and Xudong Tian and Anqi Lv and Laifu Man and Jianxiang Li and Feiyu Tao and Qihua Sun and Zhou Liang and Yushu Mu and Zhongxuan Li and Jing-Jun Zhang and Shutao Zhang and Xiaotian Li and Xingqi Xia and Jiawei Lin and Zheyu Shen and Jiahang Chen and Qiuhao Xiong and Binran Wang and Fengyuan Wang and Ziyang Ni and Bohan Zhang and Fan Cui and Changkun Shao and Qing-Hong Cao and Ming-xing Luo and Muhan Zhang and Hua Xing Zhu},
      year={2025},
      eprint={2504.16074},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      paper={https://arxiv.org/abs/2504.16074}, 
}