---
---

@article{hu2024casebasedrulebasedtransformersmath,
      abbr={ICML2024},
      title={Case-Based or Rule-Based: How Do Transformers Do the Math?}, 
      author={Yi Hu and Xiaojuan Tang and Haotong Yang and Muhan Zhang},
      year={2024},
      eprint={2402.17709},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      paper={https://arxiv.org/abs/2402.17709},
      selected={true},
      poster={https://icml.cc/media/PosterPDFs/ICML%202024/35020.png?t=1720534634.9898195},
      code={https://github.com/GraphPKU/Case_or_Rule}
}

@article{hu2023codepromptingneuralsymbolic,
      abbr={preprint},
      title={Code Prompting: a Neural Symbolic Method for Complex Reasoning in Large Language Models}, 
      author={Yi Hu and Haotong Yang and Zhouchen Lin and Muhan Zhang},
      year={2023},
      eprint={2305.18507},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      paper={https://arxiv.org/abs/2305.18507}, 
}

@article{yang2024numbercookbooknumberunderstanding,
      abbr={ICLR2025},
      title={Number Cookbook: Number Understanding of Language Models and How to Improve It}, 
      author={Haotong Yang and Yi Hu and Shijia Kang and Zhouchen Lin and Muhan Zhang},
      year={2024},
      eprint={2411.03766},
      selected={true},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      paper={https://arxiv.org/abs/2411.03766}, 
      code={https://github.com/GraphPKU/number_cookbook}
}

@article{xu2025redstardoesscalinglongcot,
      abbr={preprint},
      title={RedStar: Does Scaling Long-CoT Data Unlock Better Slow-Reasoning Systems?}, 
      author={Haotian Xu and Xing Wu and Weinong Wang and Zhongzhi Li and Da Zheng and Boyuan Chen and Yi Hu and Shijia Kang and Jiaming Ji and Yingying Zhang and Zhijiang Guo and Yaodong Yang and Muhan Zhang and Debing Zhang},
      year={2025},
      eprint={2501.11284},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      paper={https://arxiv.org/abs/2501.11284},
      selected={true},
      code={https://huggingface.co/RedStar-Reasoning}
}

@article{hu2025traininglargelanguagemodels,
      abbr={preprint},
      title={Training Large Language Models to be Better Rule Followers}, 
      author={Yi Hu and Shijia Kang and Haotong Yang and Haotian Xu and Muhan Zhang},
      year={2025},
      eprint={2502.11525},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      selected={true},
      paper={https://arxiv.org/abs/2502.11525}, 
}